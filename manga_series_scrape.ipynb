{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "manga_ids = []\n",
    "\n",
    "series_names = []\n",
    "series_synopses = []\n",
    "series_english_names = []\n",
    "series_japanese_names = []\n",
    "series_types = []\n",
    "series_volumes = []\n",
    "series_chapters = []\n",
    "series_status = []\n",
    "series_publish_time = []\n",
    "series_magazines = []\n",
    "series_popularity = []\n",
    "series_num_members = []\n",
    "series_num_favourites = []\n",
    "series_genres = []\n",
    "series_themes = []\n",
    "series_demo = []\n",
    "series_authors = []\n",
    "series_scores = []\n",
    "series_ranks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('manga_ids.csv', newline = '') as f:\n",
    "    for row in csv.reader(f):\n",
    "        manga_ids.append(row[0])\n",
    "\n",
    "f.close()\n",
    "manga_ids = manga_ids[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(data):\n",
    "    ''' \n",
    "    Parameters:\n",
    "        data: (list) The list of the data we search through\n",
    "    Outputs:\n",
    "        name: (str) Returns the name of the series\n",
    "    '''\n",
    "\n",
    "    return soup.find('span', {'itemprop': 'name'}).text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synopsis(data):\n",
    "    ''' \n",
    "    Parameters:\n",
    "        data: (list) The list of the data we search through\n",
    "    Outputs:\n",
    "        synopsis: (str) Returns the synopsis of the series\n",
    "    '''\n",
    "\n",
    "    return soup.find('span', {'itemprop': 'description'}).text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_field(name, data):\n",
    "    '''\n",
    "    Parameters:\n",
    "        name: (str) The name of the field whos existence you want to check\n",
    "        data: (list) The list of data you want to search through\n",
    "\n",
    "    Outputs:\n",
    "        index: (int) Returns index in list if found; -1 otherwise\n",
    "    '''\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        if name in data[i].find('span', {'class': 'dark_text'}).text:\n",
    "            return i\n",
    "        \n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_single(name, data):\n",
    "    ''' \n",
    "    Parameters:\n",
    "        data: (list) The list that holds the information we want to scrape\n",
    "    Outputs:\n",
    "        info: (str/None) Returns string value of the information to scrape; None if it doesn't exist\n",
    "    '''\n",
    "\n",
    "    index = check_field(name, data)\n",
    "    if index == -1:\n",
    "        return None \n",
    "    \n",
    "    if name in ('Type', 'Serialization'):\n",
    "        return data[index].contents[2].text\n",
    "    else:\n",
    "        return data[index].contents[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_multi(name, data):\n",
    "    ''' \n",
    "    Parameters:\n",
    "        data: (list) The list that holds the information we want to scrape\n",
    "    Outputs:\n",
    "        info: (str/None) Returns string value of the information to scrape; None if it doesn't exist\n",
    "    '''\n",
    "\n",
    "    index = check_field(name, data)\n",
    "    if index == -1:\n",
    "        return None\n",
    "    \n",
    "    values = data[index].find_all('span', {'itemprop': 'genre'})\n",
    "    return ','.join([val.text for val in values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_authors(data):\n",
    "    ''' \n",
    "    Parameters:\n",
    "        data: (list) The list that holds the information we want to scrape\n",
    "    Outputs:\n",
    "        authors: (str) comma-delimited sequence of the authors of the series\n",
    "    '''\n",
    "\n",
    "    index = check_field('Authors', data)\n",
    "    if index == -1:\n",
    "        return None\n",
    "    \n",
    "    authors = data[index].contents[2:-1:2]\n",
    "    return ','.join([author.text.replace(', ', ' ') for author in authors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(data):\n",
    "    ''' \n",
    "    Parameters:\n",
    "        data: (list) The list that holds the information we want to scrape\n",
    "    Outputs:\n",
    "        score: (str) The fan voted score out of 10 for the series\n",
    "    '''\n",
    "\n",
    "    index = check_field('Score', data)\n",
    "    if index == -1:\n",
    "        return None\n",
    "    \n",
    "    return data[index].find('span', {'itemprop': 'ratingValue'}).text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rank(data):\n",
    "    ''' \n",
    "    Parameters:\n",
    "        data: (list) The list that holds the information we want to scrape\n",
    "    Outputs:\n",
    "        rank: (str) The fan determined rank of the series amongst the others\n",
    "    '''\n",
    "    \n",
    "    return data.find('div', class_ = \"spaceit_pad po-r js-statistics-info di-ib\").contents[2].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for manga_id in manga_ids[:10]:\n",
    "    response = requests.get(f'https://myanimelist.net/manga/{manga_id}')\n",
    "    if response.status_code != 200:\n",
    "        print(f'Failed to scrape the web page. Restart from: {manga_id}')\n",
    "        break \n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    temp_block = soup.find('td', {'class': 'borderClass'})\n",
    "    info = temp_block.find_all('div', {'class': 'spaceit_pad'})\n",
    "\n",
    "    series_names.append(get_name(soup))\n",
    "    series_synopses.append(get_synopsis(soup))\n",
    "    series_english_names.append(get_info_single('English', info))\n",
    "    series_japanese_names.append(get_info_single('Japanese', info))\n",
    "    series_types.append(get_info_single('Type', info))\n",
    "    series_volumes.append(get_info_single('Volumes', info))\n",
    "    series_chapters.append(get_info_single('Chapter', info))\n",
    "    series_status.append(get_info_single('Status', info))\n",
    "    series_publish_time.append(get_info_single('Published', info))\n",
    "    series_magazines.append(get_info_single('Serialization', info))\n",
    "    series_popularity.append(get_info_single('Popularity', info))\n",
    "    series_num_members.append(get_info_single('Member', info))\n",
    "    series_num_favourites.append(get_info_single('Favorite', info))\n",
    "    series_genres.append(get_info_multi('Genre', info))\n",
    "    series_themes.append(get_info_multi('Theme', info))\n",
    "    series_demo.append(get_info_multi('Demographic', info))\n",
    "    series_authors.append(get_authors(info))\n",
    "    series_scores.append(get_score(info))\n",
    "    series_ranks.append(get_rank(soup))\n",
    "\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'name': series_names,\n",
    "        'english_name': series_english_names,\n",
    "        'japanese_name': series_japanese_names,\n",
    "        'synopsis': series_synopses,\n",
    "        'type': series_types,\n",
    "        'volumes': series_volumes,\n",
    "        'chapters': series_chapters,\n",
    "        'status': series_status,\n",
    "        'publishing_period': series_publish_time,\n",
    "        'genres': series_genres,\n",
    "        'themes': series_themes,\n",
    "        'authors': series_authors,\n",
    "        'demographic': series_demo,\n",
    "        'magazine': series_magazines,\n",
    "        'score': series_scores,\n",
    "        'rank': series_ranks,\n",
    "        'popularity': series_popularity,\n",
    "        'members': series_num_members,\n",
    "        'favourites': series_num_favourites\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('manga_info.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('manga_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e3ec886060125e71f64d2f8f5e7dcae200771887f0af3243723a1d274ad282f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
